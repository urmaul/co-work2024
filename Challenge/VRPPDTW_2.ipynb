{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'urmaul/co-work2024/Challenge/training_data/1adef166-1111-45fd-b722-0f817c7fa055/couriers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m file3_path \u001b[38;5;241m=\u001b[39m PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraveltimes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Read the CSV files into dataframes\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Read the CSV files into dataframes\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m couriers_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file1_path)\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m deliveries_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file2_path)\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m travel_time_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file3_path, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'urmaul/co-work2024/Challenge/training_data/1adef166-1111-45fd-b722-0f817c7fa055/couriers.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Update the PATH variable to the correct absolute path\n",
    "PATH = \"urmaul/co-work2024/Challenge/training_data/1adef166-1111-45fd-b722-0f817c7fa055/\"\n",
    "#1adef166-1111-45fd-b722-0f817c7fa055\n",
    "#1ad01be7-2897-4c4f-83f0-cfa7953cc8b8\n",
    "#large\n",
    "#ae2e3aac-1651-469c-9366-879a1142ed36\n",
    "\n",
    "# Provide the full file paths\n",
    "file1_path = PATH + \"couriers.csv\"\n",
    "file2_path = PATH + \"deliveries.csv\"\n",
    "file3_path = PATH + \"traveltimes.csv\"\n",
    "\n",
    "# Read the CSV files into dataframes\n",
    "# Read the CSV files into dataframes\n",
    "couriers_df = pd.read_csv(file1_path).apply(pd.to_numeric, errors='coerce')\n",
    "deliveries_df = pd.read_csv(file2_path).apply(pd.to_numeric, errors='coerce')\n",
    "travel_time_df = pd.read_csv(file3_path, index_col='Locations').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Ensure the index and column types are integer for travel_time_df\n",
    "travel_time_df.index = travel_time_df.index.astype(int)\n",
    "travel_time_df.columns = travel_time_df.columns.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Parameters\n",
    "#Parameters\n",
    "# Parameters - Extract columns from deliveries dataframe\n",
    "aa = pd.to_numeric(deliveries_df.iloc[:, 0], errors='coerce')\n",
    "bb = pd.to_numeric(deliveries_df.iloc[:, 2], errors='coerce')\n",
    "cc = pd.to_numeric(deliveries_df.iloc[:, 5], errors='coerce')\n",
    "\n",
    "# Calculate the max value across aa, bb, cc\n",
    "n = max(aa.max(), bb.max(), cc.max())\n",
    "pickup_locs = deliveries_df['Pickup Loc'].values.tolist()\n",
    "\n",
    "c=len(couriers_df)\n",
    "# Create a c x c identity matrix\n",
    "couriers_depot = np.eye(c)\n",
    "\n",
    "\n",
    "#Sets\n",
    "depots = couriers_df['Location'].values.tolist()\n",
    "\n",
    "# Extract the pickup and dropoff locations as lists\n",
    "pickup_locs = deliveries_df['Pickup Loc'].values.tolist()\n",
    "dropoff_locs = deliveries_df['Dropoff Loc'].values.tolist()\n",
    "\n",
    "# Use zip to combine pickup and dropoff locations element-wise into pairs\n",
    "pairs = list(zip(pickup_locs, dropoff_locs))\n",
    "\n",
    "# Parameters\n",
    "cap_utilization = deliveries_df['Capacity'].values.tolist()\n",
    "max_cap = couriers_df['Capacity'].values.tolist()\n",
    "\n",
    "# Create a vector for capacity utilization\n",
    "cap_vector = []\n",
    "\n",
    "# Add elements from max_cap to cap_vector\n",
    "for i in range(len(max_cap)):\n",
    "    cap_vector.append((i + 1, max_cap[i]))\n",
    "\n",
    "# Add elements from pairs to cap_vector\n",
    "for i in range(len(pairs)):\n",
    "    cap_vector.append((pairs[i][0], -cap_utilization[i]))  # For pickup location\n",
    "    cap_vector.append((pairs[i][1], cap_utilization[i]))  # For dropoff location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = range(1, n)\n",
    "K = range(1, c)\n",
    "\n",
    "EPS = 1.e-6\n",
    "\n",
    "tt = {}\n",
    "\n",
    "# Iterate through the dataframe rows and columns\n",
    "for i in travel_time_df.index:\n",
    "    for j in travel_time_df.columns:\n",
    "        # Assign the value at the (i, j) position to the new dictionary\n",
    "        tt[(i, j)] = travel_time_df.loc[i, j]\n",
    "\n",
    "l = {i: 1000 for i in range(1, n+1)}\n",
    "e = {i: 0 for i in range(1, n+1)}\n",
    "\n",
    "prep = {}\n",
    "\n",
    "# Initialize e and prep dictionaries\n",
    "e = {i: 0 for i in range(1, n+1)}  # Assuming n is defined elsewhere\n",
    "prep = {i: 0 for i in range(1, n+1)}\n",
    "\n",
    "for i in range(1, n+1):\n",
    "    for j in range(0, len(pickup_locs)):\n",
    "        if deliveries_df.loc[j, 'Pickup Loc'] == i:\n",
    "            a = deliveries_df.loc[j, 'Time Window Start']\n",
    "            e[i] = a  # Set e[i] only when there is a match\n",
    "            prep[i] = deliveries_df.loc[j, 'Time Window Start']\n",
    "        # Avoid overwriting non-zero values\n",
    "        elif deliveries_df.loc[j, 'Pickup Loc'] != i and e[i] == 0:\n",
    "            e[i] = 0\n",
    "            prep[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SCIP - Python Interface\n",
    "from pyscipopt import Model, quicksum, multidict\n",
    "from pyscipopt import Branchrule, SCIP_RESULT\n",
    "\n",
    "# First step is to create a new problem \n",
    "model = Model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = {}\n",
    "for kk in range(1, c+1):\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, n+1):\n",
    "            if j != i:\n",
    "                 x[i, j, kk] = model.addVar(ub=1, vtype='C', name=\"x(%s,%s,%s)\" % (i, j, kk))\n",
    "#                 x[i, j, kk] = model.addVar(ub=1, vtype='B', name=\"x(%s,%s,%s)\" % (i, j, kk))\n",
    "\n",
    "\n",
    "\n",
    "#Time variables\n",
    "t = {}\n",
    "for i in range(1, n+1):\n",
    "    t[i] = model.addVar(name=\"t(%s)\" % (i),vtype='C')\n",
    "\n",
    "# capacity variables\n",
    "q = {}\n",
    "for i in range(1, n+1):\n",
    "    q[i] = model.addVar(name=\"q(%s)\" % (i),vtype='C')       \n",
    "\n",
    "\n",
    "# Create and add decision variables directly (always first to be added)\n",
    "\n",
    "# Objective\n",
    "#model.setObjective(quicksum(t[i] for i in range(1, n+1) if i not in depots), sense=\"minimize\")\n",
    "model.setObjective(quicksum(1000*(1-x[i, j, kk]) for (i, j, kk) in x)+quicksum(t[i] for i in range(1, n+1) if i not in depots), sense=\"minimize\")\n",
    "# Min travel time\n",
    "#model.setObjective(quicksum(1000*(1-x[i, j, kk]) for (i, j, kk) in x)+quicksum(tt[i,j]*x[i, j, kk] for (i, j, kk) in x), sense=\"minimize\")\n",
    "#model.setObjective(quicksum(tt[i,j]*x[i, j, kk] for (i, j, kk) in x), sense=\"minimize\")\n",
    "\n",
    "\n",
    "# Create constraints\n",
    "#Visting constraints\n",
    "for i in range(1, n+1):\n",
    "    if i not in depots:\n",
    "        model.addCons(quicksum(x[j,i,kk] for j in range(1, n+1) for kk in range(1, c+1) if j != i and (j,i,kk) in x) == 1, \"In(%s)\"%i)\n",
    "#        model.addCons(quicksum(x[j,i,kk] for j in range(1, n+1) for kk in range(1, c+1) if j != i and (j,i,kk) in x) <= 1, \"In(%s)\"%i)\n",
    "\n",
    "\n",
    "#Flow conservation constraints\n",
    "for kk in range(1, c+1):\n",
    "   for i in range(1, n+1):\n",
    "        model.addCons(quicksum(x[i,j,kk] for j in range(1, n+1) if j != i) == quicksum(x[j,i,kk] for j in range(1, n+1) if j != i), \"flow(%s,%s)\"%(i,kk))\n",
    "\n",
    "#Flow conservation pickup and delivering -constraints\n",
    "for kk in range(1, c+1):\n",
    "    for i in range(len(pairs)):\n",
    "         model.addCons(quicksum(x[pairs[i][0],j, kk] for j in range(1, n+1)  if (pairs[i][0],j, kk) in x) == quicksum(x[j,pairs[i][1], kk] for j in range(1, n+1)  if (j,pairs[i][1], kk) in x), \"flowPD(%s,%s)\" % (i, kk))\n",
    "\n",
    "for kk in range(1, c+1):\n",
    "    for i in range(1, n+1):\n",
    "        if i in depots:\n",
    "            model.addCons(quicksum(x[i, j, kk] for j in range(1, n+1) if i != j and (i, j, kk) in x) == couriers_depot[i-1,kk-1], \"Visit(%s,%s)\" % (i,kk))\n",
    "#            model.addCons(quicksum(x[i, j, kk] for j in range(1, n+1) if i != j and (i, j, kk) in x) <= couriers_depot[i-1,kk-1], \"Visit(%s,%s)\" % (i,kk))\n",
    "\n",
    "\n",
    "\n",
    "# Time window constraints\n",
    "for i in range(1, n+1):\n",
    "    for j in range(1, n+1):\n",
    "        for kk in range(1, c+1):\n",
    "            if j not in depots and i != j:\n",
    "                M = max(l[i] + tt[i,j] - e[j], 0)\n",
    "                model.addCons(t[i] + tt[i,j] -  M*(1-x[i, j, kk])<= t[j], \"MTZ(%s,%s)\"%(i,j))  \n",
    "\n",
    "# Time window constraints latest and earliest\n",
    "for i in range(1, n+1):\n",
    "    if i not in depots:\n",
    "        model.addCons(t[i] <= l[i], \"latestTW(%s)\" % i) \n",
    "        model.addCons(t[i] >= e[i], \"earliestTW(%s)\" % i)  \n",
    " \n",
    "# coordination between time of pickup and delivery\n",
    "for i in range(len(pairs)):\n",
    "    for j in range(len(pairs)):\n",
    "        if i == j:\n",
    "            model.addCons(t[pairs[i][1]] - t[pairs[i][0]] >= 0, \"diff(%s,%s)\" % (pairs[i][0], pairs[i][1]))\n",
    "\n",
    "# Initial Capacity constraints\n",
    "for i in range(1, len(depots)+1):\n",
    "    model.addCons(q[depots[i-1]] == max_cap[i-1], \"InitialCapacity(%s)\"%depots[i-1])\n",
    "\n",
    "#capacity constraints\n",
    "for i in range(1, n+1):\n",
    "    for j in range(1, n+1):\n",
    "        for kk in range(1, c+1):\n",
    "            if j not in depots and (i,j,kk) in x: \n",
    "                model.addCons(q[i] + (max_cap[kk-1]+cap_vector[j-1][1])*x[i,j, kk] <= q[j] + max_cap[kk-1], \"Capacity(%s,%s,%s)\" % (i, j,kk))\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment the following line if you want to turn off logging from PySCIPOpt:\n",
    "model.hideOutput(False)\n",
    "\n",
    "print(\"pairs[i][0]\", pairs[0])\n",
    "\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "print(\"Optimal value:\", model.getObjVal())\n",
    "print(model.getBestSol())\n",
    "\n",
    "\n",
    "# process solution\n",
    "edges_sol = []\n",
    "edges_sol_with_values = []\n",
    "for (i, j, kk) in x:\n",
    "    val = model.getVal(x[i, j, kk])\n",
    "    if val > EPS:\n",
    "        edges_sol.append((i, j, kk))\n",
    "        edges_sol_with_values.append((i, j, kk, val))\n",
    "\n",
    "print(\"edges_sol\", edges_sol)\n",
    "print(\"edges_sol_with_values\", edges_sol_with_values) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with fractional variables\n",
    "\n",
    "\n",
    "patterns_with_vals = [\n",
    "            (eval(var.name.replace(\"t_\", \"\")), val) for var, val in zip(lpcands, lpcandssol)\n",
    "        ]\n",
    "\n",
    "self.branching_decisions = {\n",
    "            1: { # root node\n",
    "                \"together\": set(),\n",
    "                \"apart\": set(),\n",
    "            }\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
